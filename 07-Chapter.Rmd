# Statistical Spatial Interpolation

**"Compassion isn't about being nice, it's about reducing suffering for others."** -- April Wensel

## Introduction

Observations of the natural world are made at specific locations in space (and time). But we often want estimates of the observed values everywhere. This is the case when the observations are taken from a continuous field (surface). Data observed or measured at locations across a continuous field are called geostatistical data. Examples: concentrations of heavy metals across a farm field, surface air pressures measured by barometers at cities across the country, minimum air temperature values across the city on a clear, calm night.

Local averaging or spline functions are typically used for interpolation. If it is 20C here and 30C ten miles to the south, then it is 25C five miles to the south. That is a reasonable first-order assumption. But, these methods do not (1) take into account spatial autocorrelation and (2) do not estimate uncertainty about the interpolated values.

Kriging is statistical interpolation (usually spatial). It is the centerpiece of what is called 'geostatistics.' The resulting surface (kriged surface) is composed of three components. (1) Spatial trend: an increase or decrease in the values that depends on direction or a covariate (co-kriging); (2) Local spatial autocorrelation. (3) Random variation. Together the three components provide a model that is used to estimate values at any point in a specified domain.

Geostatistics is used to (1) quantify spatial correlation, (2) predict values at specific locations, (3) provide an estimate of uncertainty on the predicted values, and (4) simulation.

As we've done with areal averaged data and point pattern data (Moran's I, Ripley's K, etc), we begin with understanding how to quantify spatial autocorrelation. In geostatistics, this involves the covariance function, the correlogram function, and the variogram.

### Continuity and stationarity

* Statistical interpolation assumes the observed values are spatially homogeneous. This implies stationarity and continuity.
* Stationarity implies that the average difference in values between pairs of observations separated by a given distance (lag) is constant across the domain. 
* Continuity implies that the spatial autocorrelation depends only on the lag (and orientation) between observations. That is; spatial autocorrelation is independent of location.
* Stationarity and continuity allow different parts of the domain to be treated as "independent" samples. 
* Spatial autocorrelation can be described by a single parametric function. 

Stationarity can be weak or intrinsic. Both assume the average of the difference in values at observations separated by a lag distance $h$ is zero. That is, E$[z_i - z_j]$ = 0, where location $i$ and location $j$ are a (lag) distance $h$ apart. This implies that the interpolated surface $Z(s)$ is a random function with a constant mean ($m$) and a residual ($\varepsilon$).
$$
Z(s) = m + \varepsilon(s).
$$
The expected value (average across all values) in the domain is $m$.

Weak stationarity assumes the covariance is a function of the lag distance $h$.
$$
\hbox{cov}(z_i, z_j) = \hbox{cov}(h)
$$
where cov($h$) is called the covariogram.

Intrinsic stationarity assumes the variance of the difference in values is a function of the lag: 
$$
\hbox{var}(z_i - z_j) = \gamma(h),
$$
where $\gamma(h)$ is called the variogram. This means that the variance of $Z$ is constant and that spatial correlation is independent of location.

These assumptions are needed to get started with statistical interpolation.

### Covariogram and correlogram

Our interest will be on a parametric model for the variogram $\gamma(h)$. But to help understand the variogram, let us first consider the covariogram. 

To make things simple but with no loss in generality, we start with a 4 x 6 map of surface air temperatures in degrees C.

  21  21  20  19  18  19 
  
  26  25  26  27  29  28 
  
  32  33  34  35  30  28   
  
  34  35  35  36  32  31   

Put the values into a data vector and determine the mean and variance.
```{r chapter7}
temps <- c(21, 21, 20, 19, 18, 19, 
           26, 25, 26, 27, 29, 28, 
           32, 33, 34, 35, 30, 28, 
           34, 35, 35, 36, 32, 31)
mean(temps); var(temps)
```

To start, we focus only on the north-south direction. To compute the sample covariance function we first compute the covariance between the observed values one distance unit apart.

Mathematically
$$
\hbox{cov}(0, 1) = 1/|N(1)| \sum (z_i - Z)(z_j - Z)
$$
where $|N(1)|$ is the number of distinct observation pairs with a distance separation of one unit in the north-south direction and where $Z$ is the average over all observations. Here we let zero in the cov(0, 1) refer to the direction and the one to the distance of one unit apart. Here $|N(1)|$ = 18.

The equation for the covariance can be simplified to:
$$
\hbox{cov}(0, 1) = 1/|N(1)| \sum z_i z_j - m_{-1} m_{+1}
$$
where $m_{-1}$ is the average temperature over all rows except the first (northern most) and $m_{+1}$ is the average temperature over all rows except the last (southern most).

To simplify the notation we re-index the grid of temperatures using lexicographic (reading) order.

 1   2   3   4   5   6
 
 7   8   9   10  11  12 
 
 13  14  15  16  17  18  
  
 19  20  21  22  23  24 

Then
```{r}
mp1 <- mean(temps[1:18])
mm1 <- mean(temps[7:24])
cc <- sum(temps[1:18] * temps[7:24])/18
cc - mm1 * mp1
```

Or more generally
```{r}
N <- 18
k <- 1:N
1/N * sum(temps[k] * temps[k + 6]) - mean(temps[k]) * mean(temps[k + 6])
```

The covariance has units of the field variable squared (here $^\circ C^2$).

We also have observation pairs two units of distance apart. So we compute the cov(0, 2) in a similar way. 
$$
\hbox{cov}(0, 2) = 1/|N(2)| \sum z_i z_j - m_{-2} m_{+2}
$$
where $m_{-2}$ is the average temperature over all rows except the first two and $m_{+2}$ is the average temperature over all rows except the last two. $|N(2)|$ is the number of pairs two units apart.
```{r}
N <- 12
k <- 1:N
1/N * sum(temps[k] * temps[k + 12]) - mean(temps[k]) * mean(temps[k + 12])
```

Similarly we have observation pairs three units apart so we compute cov(0, 3) as
$$
\hbox{cov}(0, 3) = 1/|N(3)| \sum z_i z_j - m_{-3} m_{+3}
$$
```{r}
N <- 6
k <- 1:N
1/N * sum(temps[k] * temps[k + 18]) - mean(temps[k]) * mean(temps[k + 18])
```

There are no observation pairs four units apart in the north-south direction so we are finished. The covariogram is a plot of the covariance values as a function of lagged distance. Let h be the lagged distance, then

h      |  cov(h)  
-------|--------  
(0, 1) |  15  
(0, 2) |   3  
(0, 3) |   1  

It is convenient to have a measure of co-variability that is dimensionless. This is obtained by dividing the covariance at lagged distance $h$ by the covariance at lag zero. This is the correlogram. Values of the correlogram range from 0 to +1.

### Variogram

The covariogram is a decreasing function of lag. The variogram is the multiplicative inverse of the covariogram. 

Mathematically: var($z_i - z_j$) for locations i and j. The semivariogram is 1/2 the variogram. If location i is near location j, the difference in the values will be small and so too will the variance of their differences, in general. If location i is far from location j, the difference in values will be large and so too will the variance of their differences.

In practice we have a set of observations and we compute a variogram. We call this the sample (or empirical) variogram. Let $t_i = (x_i, y_i)$  be the ith location and $h_{i,j} = t_j - t_i$ be the vector connecting location $t_i$ with location $t_j$. Then the sample variogram is defined as
$$
\gamma(h) = \frac{1}{2N(h)} \sum^{N(h)} (z_i - z_j)^2
$$
where $N(h)$ is the number of observation pairs a distance of $h$ units apart.

The variogram assumes intrinsic stationarity so the values need to be detrended first.

The sample variogram is characterized by a set of points the values of which generally increase as $h$ increases before leveling off (reaching a plateau).

### Terminology

Let's begin with a plot with labels. Make sure the {geoR} package is installed. The code is done using the base graphics commands and the plot method from the package.
```{r}
library(geoR)
plot(variog(s100, max.dist = 1), 
     xlab = "Lagged Distance (h)",
     ylab = expression(paste(gamma,"(h)")), 
     las = 1, pch = 16)
abline(h = 0)
abline(h = .15, col = "red")
arrows(0, 0, x1 = 0, y1 = .15, length = .1)
text(0, y = .05, labels = "nugget", pos=4)
abline(h = .9, col = "red")
arrows(0, .15, x1 = 0, y1 = .9, length = .1)
text(0, y = .8, labels="sill (partial sill)", pos=4)
abline(v = .6, col = "red")
arrows(0, 1, x1 = .6, y1 = 1, length = .1)
text(.4, y = 1.04, labels = "range")
```

* Lag (lag distance): Relative distance between observation locations.
* Nugget (nugget, nugget variance, or nugget effect): The height of the variogram at zero lag. The nugget is the variation in the values at the observation locations without regard to spatial variation. Related to the observation (or measurement) precision.
* Sill: The height of the variogram at which the values are uncorrelated.
* Relative nugget effect: The ratio of the nugget to the sill expressed as a percentage.
* Range: The distance beyond which the values are uncorrelated. The range is indicated on the empirical variogram as the position along the horizontal axis where values of the variogram reach a constant height.

Additional terms.
* Isotropy: The condition in which spatial correlation is the same in all directions.
* Anisotropy: (an-I-so-trop-y) spatial correlation is stronger or more persistent in some directions.
* Directional variogram: Distance and direction are important in characterizing the spatial correlations. Otherwise the variogram is called omni-directional.
* Azimuth ($\theta$): Defines the direction of the variogram in degrees.The azimuth is measured clockwise from north.
* Lag spacing: The distance between successive lags is called the lag spacing or lag increment.
* Lag tolerance: The distance allowable for observational pairs at a specified lag. With arbitrary observation locations there will be no observations exactly a lag distance from any observation. Lag tolerance provides a range of distances to be used for computing values of the variogram at a specified lag.

### Variogram Models

Computing the sample variogram is the first step in modeling geostatistical data. The next step is to fit a model to these variogram estimates. We replace a scatter of points with a statistical model. 

The model is important since the sample variogram is made only at specified lag distances (with specified lag tolerance and azimuth). We need a continuous function that varies smoothly across all lags.

Variogram models come from different families. The decision includes (1) choosing the model family and (2) determining the parameters: nugget, sill, and range.

The exponential model family reaches the sill asymptotically. The range (a) is defined as the lag distance at which gamma reaches 95% of the sill.
```{r}
c0 <- .1
c1 <- 2.1
a <- 1.3
curve(c0 + c1*(1 - exp(-3*x/a)), 
      from = .01, to = 3, 
      xlab = "h", 
      ylab = expression(paste(hat(gamma), "(h)")), 
      las = 1)
```

The spherical model family is piece wise reaching the sill at x = 1 (here).
```{r}
curve(c0 + c1*(3*x/2 - x^3/2),
      from = .01, to = 1,
      xlab = "h",
      ylab = expression(paste(hat(gamma), "(h)")), 
      las = 1)
```

The Gaussian model family is sigmoidal. It is used when the data exhibit strong correlations at the shortest lag distances.  The inflection point of the model occurs at $\sqrt{a/6}$.
```{r}
curve(c0 + c1*(1 - exp(-3*x^2/a^2)),
      from = .01, to = 3, 
      xlab = "h", 
      ylab = expression(paste(hat(gamma), "(h)")),
      las = 1)
```

Other families include

* Linear models: $\hat \gamma(h)$ = c0 + b * h.
* Power models:  $\hat \gamma(h)$ = c0 + b * h$^\lambda$.

These models have no sill.

Choosing a variogram family is largely done by eyeballing the shape of the sample variogram. Then, given a sample variogram computed from a set of spatial observations and a choice of family, the parameters of the variogram model are determined by a weighted least-squares (WLS) algorithm. There are other ways to determine the parameters including by eye, and by the method of maximum likelihoods, but WLS is less erratic than other methods and it requires fewer assumptions about the distribution of the data.

### Kriging

The final step is kriging. Kriging interpolates the observed data using the variogram model. It was developed by a South African miner (D.G. Krige) as a way to improve estimates of where ore reserves might be located. Extraction costs are reduced substantially if good predictions can be made of where the ore resides given samples taken across the mine.

A kriged estimate is a weighted average of the observations where the weights are based on the variogram model. The kriged estimates are optimal in the sense that they minimize the error variance. The type of kriging depends on the characteristics of the observations and the purpose of interpolation.

* Simple kriging assumes a known constant mean for the domain.  
* Ordinary kriging assumes an unknown constant mean.  
* Universal kriging assumes an unknown linear or nonlinear trend in the mean.  

The steps are:

1. Examine the observations for trends and isotropy.
2. Compute an empirical variogram.
3. Fit a variogram model to the empirical variogram.
4. Create an interpolated surface using kriging.
